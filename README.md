## Классификатор ответов для образовательной игры по ML/DL
**Студент: Спиридонов Д.В., группа МОВС 2023**

## Содержание
- [Формулировка задачи](#формулировка-задачи)
- [Данные](#данные)
- [Подход к моделированию](#подход-к-моделированию)
- [Способ предсказания](#способ-предсказания)
- [План работ](#план-работ)
- [ДЗ-2](#дз-2)

## Формулировка задачи
**Что я делаю:**
Цель проекта — разработать модель-классификатор на базе дообученного BERT, которая будет оценивать ответы игроков на вопросы по темам ML/DL по шкале от 1 до 4 (в зависимости от успешности результатов шкала может поменяться).
Этот классификатор станет частью бэкенда игры - игроки будут давать ответы на теоретические вопросы, а модель оценивать их ответы

**Зачем это нужно:**
Под оценку ответов игроков подвязываются различные игровые механики, правильные ответы дают преимущества над другими игроками

## Данные
**Источники данных:**

1. Для дообучения (NSP, MTP) материалы по ML/DL из открытых источников. Данные будут отфильтрованы и конвертированы в нужный формат для задач Next Sentence Prediction и Masked Token Prediction

2. Для финальной задачи классификации подготовлю датасет формата вопрос – ответ – оценка

**Особенности и проблемы:**
- Необходима фильтрация некачественных данных
- Собрать достаточное количество данных для NSP/MTP
- Для классификатора собрать и разметить несколько тысяч примеров

## Подход к моделированию
**Модель:**
- Базовая модель: `microsoft/deberta-v3-base` (HuggingFace).
- Этапы:
   - Дообучение BERT на NSP для лучшего понимания контекстной связности ML/DL текстов
   - Дообучение BERT на MTP для улучшения понимания лексики
   - Файнтюнинг итоговой модели на задачу классификации ответов

 **Управление экспериментами:**
 - Используем MLflow для отслеживания экспериментов
 - DVC для версионирования данных и моделей

**Инструменты и библиотеки:**
- `transformers` (HuggingFace)
- `torch` (PyTorch)
- `datasets` (HuggingFace)
- `scikit-learn` для метрик

**Схема:**

        ┌─────────────────────────┐
        │      Исходные тексты    │
        └───────┬─────────────────┘
                │ Очистка и предобработка
                v
        ┌───────────────────────────┐
        │        Обучение NSP       │
        └───────────┬───────────────┘
                    │ Загрузка модели после NSP
                    v
        ┌───────────────────────────┐
        │        Обучение MTP       │
        └───────────┬───────────────┘
                    │ Загрузка модели после MTP
                    v
        ┌───────────────────────────────┐
        │ Классификация Вопрос–Ответ    │
        │        (оценка 1–4)           │
        └───────────┬───────────────────┘
                    v
             Модель классификации


## Способ предсказания
**Предполагаемый пайплайн после обучения:**

1. **API сервис:**
   Модель будет обёрнута в API сервис

2. **Шаги предсказания:**
   - Получение вопроса и ответа от игрового бэкенда
   - Предобработка - токенизация текста
   - После инференса получаем логиты классов
   - Интерпретируем результат и передаем скор клиенту

## План работ

**Этап 1:**
- Сбор и очистка текстов по ML/DL
- Формирование датасетов для NSP (пары предложений) и MTP (тексты с маскированными токенами)
- Настройка окружения, подготовка кода для обучения и логирования

**Этап 2:**
- Обучение BERT на NSP
- Оценка качества угадывания следующего предложения на валидационном датасете

**Этап 3:**
- Обучение модели на MTP
- Оценка качества восстановления маскированных токенов
- Подготовка финального датасета для классификации

**Этап 4:**
- Файнтюнинг модели для классификации ответов
- Оценка качества
- Обёртка модели в Fast API

---


## ДЗ-2

1. Нарисуем структуру проекта командой
```
tree -a -I '__pycache__|*.pyc|.git|lightning_logs|*.idea'
```

```
.
├── ag_news_classifier
│   ├── bert_model.py
│   ├── config.py
│   ├── dataset.py
│   ├── infer.py
│   ├── __init__.py
│   ├── train.py
├── commands.py
├── Dockerfile
├── .gitignore
├── poetry.lock
├── .pre-commit-config.yaml
├── pyproject.toml
└── README.md

```
2. В корневой директории проекта создана отдельная директорию для сорсов ag_news_classifier
3. Убеждаемся что все зависимости зафиксированы в pyproject.toml, отсутствуют избыточные пакеты
4. Подготовим Dockerfile с валидным для проекта окружением, использовать его мы можем через
```
docker build -t ag_news_classifier .
docker run -d --name ag_news ag_news_classifier
docker exec -it ag_news python commands.py train
docker exec -it ag_news python commands.py infer --text "Hello world"
```
5. Проверим что `pre-commit run -a` выдает зеленый результат, присутствуют хуки black, isort, flake8. Также установим сначала `pre-commmit` хуки командой `pre-commit install`
6. Пока взял данные обучения не для диплома, а c huggingface датасет ag_news. Данных беру минимум для быстрого обучения, качество предсказаний пока неважно. Модель будет похожа на ту, что реализовал сейчас.
7. Запустить обучение (вместе с тестированием и валидацией) и инференс можем при помощи команд
```
poetry install
poetry shell
python commands.py train
python commands.py infer --text "Hello world"
```
