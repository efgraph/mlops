## Классификатор ответов для образовательной игры по ML/DL  
**Студент: Спиридонов Д.В., группа МОВС 2023**

## Содержание
- [Формулировка задачи](#формулировка-задачи)
- [Данные](#данные)
- [Подход к моделированию](#подход-к-моделированию)
- [Способ предсказания](#способ-предсказания)
- [План работ](#план-работ)

## Формулировка задачи
**Что я делаю:**  
Цель проекта — разработать модель-классификатор на базе дообученного BERT, которая будет оценивать ответы игроков на вопросы по темам ML/DL по шкале от 1 до 4 (в зависимости от успешности результатов шкала может поменяться).
Этот классификатор станет частью бэкенда игры - игроки будут давать ответы на теоретические вопросы, а модель оценивать их ответы

**Зачем это нужно:**  
Под оценку ответов игроков подвязываются различные игровые механики, правильные ответы дают преимущества над другими игроками

## Данные
**Источники данных:**

1. Для дообучения (NSP, MTP) материалы по ML/DL из открытых источников. Данные будут отфильтрованы и конвертированы в нужный формат для задач Next Sentence Prediction и Masked Token Prediction

2. Для финальной задачи классификации подготовлю датасет формата вопрос – ответ – оценка

**Особенности и проблемы:**
- Необходима фильтрация некачественных данных
- Собрать достаточное количество данных для NSP/MTP
- Для классификатора собрать и разметить несколько тысяч примеров

## Подход к моделированию
**Модель:**  
- Базовая модель: `microsoft/deberta-v3-base` (HuggingFace).
- Этапы:
   - Дообучение BERT на NSP для лучшего понимания контекстной связности ML/DL текстов
   - Дообучение BERT на MTP для улучшения понимания лексики
   - Файнтюнинг итоговой модели на задачу классификации ответов

 **Управление экспериментами:** 
 - Используем MLflow для отслеживания экспериментов
 - DVC для версионирования данных и моделей

**Инструменты и библиотеки:**  
- `transformers` (HuggingFace)  
- `torch` (PyTorch)  
- `datasets` (HuggingFace)  
- `scikit-learn` для метрик

**Схема:**

        ┌─────────────────────────┐
        │      Исходные тексты    │
        └───────┬─────────────────┘
                │ Очистка и предобработка
                v
        ┌───────────────────────────┐
        │        Обучение NSP       │
        └───────────┬───────────────┘
                    │ Загрузка модели после NSP
                    v
        ┌───────────────────────────┐
        │        Обучение MTP       │
        └───────────┬───────────────┘
                    │ Загрузка модели после MTP
                    v
        ┌───────────────────────────────┐
        │ Классификация Вопрос–Ответ    │
        │        (оценка 1–4)           │
        └───────────┬───────────────────┘
                    v
             Модель классификации


## Способ предсказания
**Предполагаемый пайплайн после обучения:**

1. **API сервис:**  
   Модель будет обёрнута в API сервис 

2. **Шаги предсказания:**  
   - Получение вопроса и ответа от игрового бэкенда
   - Предобработка - токенизация текста
   - После инференса получаем логиты классов
   - Интерпретируем результат и передаем скор клиенту

## План работ

**Этап 1:**
- Сбор и очистка текстов по ML/DL
- Формирование датасетов для NSP (пары предложений) и MTP (тексты с маскированными токенами)
- Настройка окружения, подготовка кода для обучения и логирования

**Этап 2:**
- Обучение BERT на NSP
- Оценка качества угадывания следующего предложения на валидационном датасете

**Этап 3:**
- Обучение модели на MTP
- Оценка качества восстановления маскированных токенов
- Подготовка финального датасета для классификации

**Этап 4:**
- Файнтюнинг модели для классификации ответов
- Оценка качества
- Обёртка модели в Fast API

---
